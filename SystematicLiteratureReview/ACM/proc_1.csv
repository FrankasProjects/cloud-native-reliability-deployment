"Item type","Authors","Title","Publication year","Pages","Publisher","Address","Proceedings title","Conference location","Date published","ISBN","URLs","DOI","Abstract","Keywords","Sub-type","Series"
"Conference Paper","Murthy MK,Sanjay HA,Ashwini JP","Pricing Models and Pricing Schemes of IaaS Providers: A Comparison Study","2012","143–147","Association for Computing Machinery","New York, NY, USA","Proceedings of the International Conference on Advances in Computing, Communications and Informatics","Chennai, India","2012","9781450311960","https://doi.org/10.1145/2345396.2345421;http://dx.doi.org/10.1145/2345396.2345421","10.1145/2345396.2345421","""Cloud Computing"" is one of the most significant advances in information technology since the rise of the global Internet network. The cost effectiveness of the cloud computing is one of the reason for its popularity. The cost can be further reduced by the customer by carefully selecting the cloud service provider, according to his/her requirement.This work is an attempt to list the different pricing models and pricing schemes used by some of the popular IaaS providers and also to understand how the price varies for the same requirement in different IaaS providers. This survey helps the customers to understand the different pricing models and to choose the better IaaS provider depending on his/her requirement.","storage space, cloud computing, IaaS, pricing models","","ICACCI '12"
"Conference Paper","Kandi MM,Yin S,Hameurlain A","An Integer Linear-Programming Based Resource Allocation Method for SQL-like Queries in the Cloud","2018","161–166","Association for Computing Machinery","New York, NY, USA","Proceedings of the 33rd Annual ACM Symposium on Applied Computing","Pau, France","2018","9781450351911","https://doi.org/10.1145/3167132.3167148;http://dx.doi.org/10.1145/3167132.3167148","10.1145/3167132.3167148","Cloud computing has emerged as a paradigm for delivering Information Technology services over Internet. Services are provided according to a pricing model and meet requirements that are specified in Service Level Agreements (SLA). Recently, most of cloud providers include services for DataBase (DB) querying dedicated to run on MapReduce platform and a virtualized architecture. Classical resource allocation methods for query optimization need to be revised to handle the pricing models in cloud environnements. In this work, we propose a resource allocation method for the query optimization in the cloud based on Integer Linear-Programming (ILP). The proposed linear models can be implemented in any fast solver for ILP. The method is compared with some existing greedy algorithms. Experimental evaluation shows that the solution offers a good trade-off between the allocation quality and allocation cost.","integer linear-programming, query optimization, mapreduce, PaaS, cloud computing, resource allocation","","SAC '18"
"Conference Paper","Ma D,Huang J","The Pricing Model of Cloud Computing Services","2012","263–269","Association for Computing Machinery","New York, NY, USA","Proceedings of the 14th Annual International Conference on Electronic Commerce","Singapore, Singapore","2012","9781450311977","https://doi.org/10.1145/2346536.2346586;http://dx.doi.org/10.1145/2346536.2346586","10.1145/2346536.2346586","Cloud computing service providers offer computing resource as a utility and software as a service over network. Many believe that Cloud computing is making an industry-wise paradigm shift for IT use. Besides its technique issues, the business feature of Cloud computing attracts our interests. Specifically the practice of Amazon EC2 introduces an interesting pricing scheme. Amazon provides users with virtual computing instances as a combination of interruptible service (i.e., spot instance) and uninterruptible service (i.e., on-demand and reserved instance). Spot instance is charged at a per use price which is dynamically changing over time; users of spot instance face the risk of service termination on the provider's side. In this paper, we build a multiple-stage game to study users' best job submission strategy under such a mixed pricing scheme, and to analyze the potential benefits and influence of such pricing scheme. We identify user-segments that will take different job submission strategies, and show that users should reserve resource for future high-value job arrivals. We also conduct numerical investigations to demonstrate how the outcome and best strategy vary according to the external market conditions.","pricing model, multi-stage game, cloud computing","","ICEC '12"
"Conference Paper","Konstantinos K,Persefoni M,Evangelia F,Christos M,Mara N","Cloud Computing and Economic Growth","2015","209–214","Association for Computing Machinery","New York, NY, USA","Proceedings of the 19th Panhellenic Conference on Informatics","Athens, Greece","2015","9781450335515","https://doi.org/10.1145/2801948.2802000;http://dx.doi.org/10.1145/2801948.2802000","10.1145/2801948.2802000","Cloud computing, is a rapidly evolving type of internet- based computing model that relies on sharing computing resources, rather than having local servers or personnel to handle them. It has already been adopted by a significant number of Small and Medium Enterprises (SMEs) as a business advantage able to improve their business environment and help them be more efficient and productive. Due to its beneficial characteristics, as flexibility of cost and scalability, cloud computing has the potential to transform the global ICT market techniques and contribute to the boost of economic growth. The provision of cloud computing services is a new and very promising business model and cloud service providers are already enjoying growing profits.This paper seeks to highlight the economic benefits of cloud computing adoption, its impact on the economic growth of a country, and to explore its diffusion using evidence from the European area. Another main objective is the demonstration of the economic benefits an SME can achieve by adopting cloud services instead of proprietary infrastructures. A case study of a new company entering the market is considered and the corresponding calculations are based on a software tool developed by our research team for the calculation of the total cost of ownership (TCO). Results, will reveal the economic benefits of the cloud and its contribution to the economic growth.","cloud computing, economic growth, cloud provider, total cost of ownership, ICT market","","PCI '15"
"Conference Paper","Lee YC,Wang C,Zomaya AY,Zhou BB","Profit-Driven Service Request Scheduling in Clouds","2010","15–24","IEEE Computer Society","USA","Proceedings of the 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing","","2010","9780769540399","https://doi.org/10.1109/CCGRID.2010.83;http://dx.doi.org/10.1109/CCGRID.2010.83","10.1109/CCGRID.2010.83","A primary driving force of the recent cloud computing paradigm is its inherent cost effectiveness. As in many basic utilities, such as electricity and water, consumers/clients in cloud computing environments are charged based on their service usage, hence the term ‘pay-per-use’. While this pricing model is very appealing for both service providers and consumers, fluctuating service request volume and conflicting objectives (e.g., profit vs. response time) between providers and consumers hinder its effective application to cloud computing environments. In this paper, we address the problem of service request scheduling in cloud computing systems. We consider a three-tier cloud structure, which consists of infrastructure vendors, service providers and consumers, the latter two parties are particular interest to us. Clearly, scheduling strategies in this scenario should satisfy the objectives of both parties. Our contributions include the development of a pricing model—using processor-sharing—for clouds, the application of this pricing model to composite services with dependency consideration (to the best of our knowledge, the work in this study is the first attempt), and the development of two sets of profit-driven scheduling algorithms.","cloud computing, mashup services, scheduling, processor-sharing, market-based resource allocation","","CCGRID '10"
"Conference Paper","Bhattacharya K,Bichler M,Tai S","ICSE Cloud 09: First International Workshop on Software Engineering Challenges for Cloud Computing","2009","482–483","IEEE Computer Society","USA","Proceedings of the 2009 31st International Conference on Software Engineering: Companion Volume","","2009","9781424434954","https://doi.org/10.1109/ICSE-COMPANION.2009.5071073;http://dx.doi.org/10.1109/ICSE-COMPANION.2009.5071073","10.1109/ICSE-COMPANION.2009.5071073","Cloud Computing has emerged as a new paradigm for deploying, managing and offering services through a shared infrastructure. The projected benefits of cloud computing are very compelling both from a cloud consumer as well as a cloud services provider perspective: ease of deployment of services; low capital expenses and constant operational expenses leading to variable pricing schemes and reduced opportunity costs; leveraging the economies of scale for both services providers and users of the cloud. However, the actual realization of these perceived benefits are far from being well-achieved and pose a broad range of interesting questions.","","","ICSE '09 COMPANION"
"Conference Paper","Liu J,Goraczko M,James S,Belady C,Lu J,Whitehouse K","The Data Furnace: Heating up with Cloud Computing","2011","15","USENIX Association","USA","Proceedings of the 3rd USENIX Conference on Hot Topics in Cloud Computing","Portland, OR","2011","","","","In this paper, we argue that servers can be sent to homes and office buildings and used as a primary heat source. We call this approach the Data Furnace or DF. Data Furances have three advantages over traditional data centers: 1) a smaller carbon footprint 2) reduced total cost of ownership per server 3) closer proximity to the users. From the home owner's perspective, a DF is equivalent to a typical heating system: a metal cabinet is shipped to the home and added to the ductwork or hot water pipes. From a technical perspective, DFs create new opportunities for both lower cost and improved quality of service, if cloud computing applications can exploit the differences in the cost structure and resource profile between Data Furances and conventional data centers.","","","HotCloud'11"
"Conference Paper","Mihailescu M,Teo YM","Dynamic Resource Pricing on Federated Clouds","2010","513–517","IEEE Computer Society","USA","Proceedings of the 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing","","2010","9780769540399","https://doi.org/10.1109/CCGRID.2010.123;http://dx.doi.org/10.1109/CCGRID.2010.123","10.1109/CCGRID.2010.123","Current large distributed systems allow users to share and trade resources. In cloud computing, users purchase different types of resources from one or more resource providers using a fixed pricing scheme. Federated clouds, a topic of recent interest, allows different cloud providers to share resources for increased scalability and reliability. However, users and providers of cloud resources are rational and maximize their own interest when consuming and contributing shared resources. In this paper, we present a dyanmic pricing scheme suitable for rational users requests containing multiple resource types. Using simulations, we compare the efficiency of our proposed strategy-proof dynamic scheme with fixed pricing, and show that user welfare and the percentage of successful requests is increased by using dynamic pricing.","","","CCGRID '10"
"Conference Paper","Dietrich J,Tandler J,Sui L,Meyer M","The PrimeGame Revolutions: A Cloud-Based Collaborative Environment for Teaching Introductory Programming","2015","8–12","Association for Computing Machinery","New York, NY, USA","Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference","Adelaide, SA, Australia","2015","9781450337960","https://doi.org/10.1145/2811681.2811683;http://dx.doi.org/10.1145/2811681.2811683","10.1145/2811681.2811683","The PrimeGame is an established mathematical programming game that has been used successfully in undergraduate computer science teaching since 2003. To meet the increasing demand for innovative programming tools in undergraduate tertiary and secondary education, we have created SoGaCo, a novel platform to deliver the PrimeGame and similar games to a wide audience via standard web browsers. SoGaCo is designed to have a very low total cost of ownership. This is achieved by enabling teachers to provision a customised collaborative development environment on commodity cloud computing infrastructure. Amongst the unique features of the platform are its social networking features and support for polyglot programming.In this paper, we describe the requirements for this system, its design and implementation. We focus on how the scalability and security challenges of an open web-based development environment are addressed. This includes a discussion of the sandboxing and verification techniques we have developed in order to safeguard server-side code execution on the Java Virtual Machine.","","","ASWEC ' 15 Vol. II"
"Conference Paper","Konstantinou I,Floros E,Koziris N","Public vs Private Cloud Usage Costs: The StratusLab Case","2012","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Workshop on Cloud Computing Platforms","Bern, Switzerland","2012","9781450311618","https://doi.org/10.1145/2168697.2168700;http://dx.doi.org/10.1145/2168697.2168700","10.1145/2168697.2168700","Cloud computing claims to offer multiple advantages comparing to ""traditional"" computing infrastructures. These include among others: energy efficiency, reduction of the overall administration costs, better utilization of hardware resources by co-hosting multiple services environments, etc. This paper reports on the experience gained during the provision of an IaaS cloud service in the context of the StratusLab project and provides quantitative economic analysis of the total cost of ownership of such infrastructure by calculating the infrastructure, maintenance and operational cost. The analysis continues with the cost comparison of the private cloud against the popular Amazon's EC2 public cloud service by utilizing the collected StratusLab usage traces for a period of one year. It is shown that with an average utilization of 70%, a small cluster of 20 machines could amortize its total cost in a period of 2-3 years while offering the same rates compared to Amazon cloud if it were offered on a pay-as-you go basis.","","","CloudCP '12"
"Conference Paper","Klaver L,van der Knaap T,van der Geest J,Harmsma E,van der Waaij B,Pileggi P","Towards Independent Run-Time Cloud Monitoring","2021","21–26","Association for Computing Machinery","New York, NY, USA","Companion of the ACM/SPEC International Conference on Performance Engineering","Virtual Event, France","2021","9781450383318","https://doi.org/10.1145/3447545.3451180;http://dx.doi.org/10.1145/3447545.3451180","10.1145/3447545.3451180","Cloud computing services are integral to the digital transformation. They deliver greater connectivity, tremendous savings, and lower total cost of ownership. Despite such benefits and benchmarking advances, costs are still quite unpredictable, performance is unclear, security is inconsistent, and there is minimal control over aspects like data and service locality. Estimating performance of cloud environments is very hard for cloud consumers. They would like to make informed decisions about which provider better suits their needs using specialized evaluation mechanisms. Providers have their own tools reporting specific metrics, but they are potentially biased and often incomparable across providers. Current benchmarking tools allow comparison but consumers need more flexibility to evaluate environments under actual operating conditions for specialized applications. Ours is early stage work and a step towards a monitoring solution that enables independent evaluation of clouds for very specific application needs. In this paper, we present our initial architecture of the Cloud Monitor that aims to integrate existing and new benchmarks in a flexible and extensible way. By way of a simplistic demonstrator, we illustrate the concept. We report some preliminary monitoring results after a brief time of monitoring and are able to observe unexpected anomalies. The results suggest an independent monitoring solution is a powerful enabler of next generation cloud computing, not only for the consumer but potentially the whole ecosystem.","run-time monitoring, performance evaluation, benchmarking, cloud computing","","ICPE '21"
"Conference Paper","Chi R,Qian Z,Lu S","A Game Theoretical Method for Auto-Scaling of Multi-Tiers Web Applications in Cloud","2012","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fourth Asia-Pacific Symposium on Internetware","Qingdao, China","2012","9781450318884","https://doi.org/10.1145/2430475.2430478;http://dx.doi.org/10.1145/2430475.2430478","10.1145/2430475.2430478","Cloud computing is a newly emerging reliable and scalable paradigm in which customers pay for cloud resources they use on demand. However, current auto-scaling mechanisms in cloud lack the critical self-adaption policy which helps application providers decide on when and how to reallocate resources. Furthermore, virtualization techniques can not ensure an absolute isolation between multiple virtual machines sharing the same physical resource, which leads to some customers paying unfairly for heavy-loaded resource under a widely-adopted fixed pricing scheme.In this paper, we present a global performance-to-price model based on game theory, in which each application is considered as a selfish player attempting to guarantee QoS requirements and simultaneously minimize the resource cost. Then we apply the idea of Nash equilibrium to obtain the appropriate allocation, and an approximated solution is proposed to obtain the Nash equilibrium, ensuring that each player is charged fairly for their desired performance. First, each player maximizes its utility independently without considering the placement of virtual machines. Then based on the initial allocation, each player reaches its optimal placement solely without considering others' interference. Finally we propose an evolutionary algorithm which step by step updates the global resource allocation based on the initial optimal allocation and placement.","game theory, resource allocation, web application, auto scaling, cloud computing, QoS","","Internetware '12"
"Conference Paper","Idziorek J,Tannian M,Jacobson D","Modeling Web Usage Profiles of Cloud Services for Utility Cost Analysis","2011","3323–3334","Winter Simulation Conference","Phoenix, Arizona","Proceedings of the Winter Simulation Conference","","2011","","","","Early proponents of public cloud computing have come to identify cost savings a key factor for adoption. However, the adoption and hosting of a web application in the cloud does not provide any such guarantees. This is in part due to the utility pricing model that dictates the cost of public cloud resources. In this work we seek to model and simulate data usage for a web application for the purpose of utility cost analysis. Although much research has been performed in the area of web usage mining, previously proposed models are unable to accurately model web usage profiles for a specific web application. In this paper, we present a simulation model and corresponding algorithm to model web usage based on empirical observations. The validation of the proposed model shows that the simulated output conforms to that of what was observed and is within acceptable tolerance limits.","","","WSC '11"
"Conference Paper","Ponte N,Trinta F,Viana R,Andrade R,Garcia V,Assad R","A Service-Oriented Architecture for Billing Resources in IaaS Cloud Platforms","2015","1719–1721","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th Annual ACM Symposium on Applied Computing","Salamanca, Spain","2015","9781450331968","https://doi.org/10.1145/2695664.2719244;http://dx.doi.org/10.1145/2695664.2719244","10.1145/2695664.2719244","Cloud Computing is a recent paradigm where different IT resources, such as applications or hardware, are quickly provisioned to customers through a pay per use model. Many research studies have already been conducted concerning billing services for cloud computing, but they lack on flexibility to establish how resources are defined and monitored. In fact, current solutions seem also very dependent on specific cloud infrastructures. This paper proposes an architecture for billing cloud services decoupled from specific providers, named as aCCountS. This service is complemented by a Domain Specific Language that allows the specification of flexible pricing policies. Such policies aims at supporting cloud billing requirements collected from our literature survey, allowing pricing schemes that meet different customer profiles. Based on this architecture, a prototype has been implemented and tested to validate our proposal in two different cloud infrastructures. Experiments confirmed that (i) the architecture hasn't dependencies of specific IaaS provider and (ii) the charging procedures are done correctly.","infrastructure as a service, cloud computing, pricing","","SAC '15"
"Conference Paper","Nasiriani N,Kesidis G,Wang D","Public Cloud Differential Pricing Design Under Provider and Tenants Joint Demand Response","2018","21–32","Association for Computing Machinery","New York, NY, USA","Proceedings of the Ninth International Conference on Future Energy Systems","Karlsruhe, Germany","2018","9781450357678","https://doi.org/10.1145/3208903.3208938;http://dx.doi.org/10.1145/3208903.3208938","10.1145/3208903.3208938","As the cloud computing market matures, effective pricing design remains a challenging problem. Electricity is a major contributor to the cloud's recurring costs and may increase significantly in the near future. As the cloud market gets more competitive, there will be a need for more cost-conscious dynamic pricing design. Additionally, today's cloud provider's pricing mechanisms act almost oblivious to the fact that the large tenants of the cloud are able to perform automated demand response in the form of delaying and dropping jobs. In this work we introduce differential dynamic pricing which provides different tenants with tailored prices according to their price sensitivity, while accounting for each tenant's energy costs. Furthermore, the cloud providers can engage in demand response to utility prices using on-site batteries. Battery management complicates things further, as it brings in additional costs, e.g., wear-and-tear, which is challenging to attribute to each tenant. So, we use virtual battery management which accounts for individual tenant's usage of batteries. We also, show how virtual battery management can alleviate possible price fluctuations and act in synergy with differential dynamic pricing scheme and result in a less variable and more predictable (stable) pricing framework, called Stable Differential Dynamic Pricing (SD2P). We navigate different real-world IBM tenants' incident power demands with different price elasticities in conjunction with real-world electricity prices, and realistic battery degradation costs, to show the efficacy of our pricing mechanism. We show that under SD2P cloud's profit increases up to 31% while average tenants' utility increases up to 18%. Prices under SD2P exhibit up to 54% less variation compared to other dynamic pricing schemes, as a result of engaging the batteries at times of energy price spikes.","Differential Pricing, Cloud Provider, Dynamic Pricing, Demand Response","","e-Energy '18"
"Conference Paper","Pires FL,Báran B","A Virtual Machine Placement Taxonomy","2015","159–168","IEEE Press","Shenzhen, China","Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing","","2015","9781479980062","https://doi.org/10.1109/CCGrid.2015.15;http://dx.doi.org/10.1109/CCGrid.2015.15","10.1109/CCGrid.2015.15","Cloud computing datacenters dynamically provide millions of virtual machines (VMs) in actual cloud markets. In this context, Virtual Machine Placement (VMP) is one of the most challenging problems in cloud infrastructure management, considering the large number of possible optimization criteria and different formulations that could be studied. VMP literature include relevant research topics such as energy efficiency, Service Level Agreement (SLA), Quality of Service (QoS), cloud service pricing schemes and carbon dioxide emissions; all of them with high economical and ecological impact. This work classifies an extensive up-to-date survey of the most relevant VMP literature proposing a novel taxonomy in order to identify research opportunities and define a general vision on this research area.","taxonomy, optimization, scheduling, placement, cloud computing, consolidation","","CCGRID '15"
"Conference Paper","Mihailescu M,Teo YM","The Impact of User Rationality in Federated Clouds","2012","620–627","IEEE Computer Society","USA","Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (Ccgrid 2012)","","2012","9780769546919","https://doi.org/10.1109/CCGrid.2012.127;http://dx.doi.org/10.1109/CCGrid.2012.127","10.1109/CCGrid.2012.127","With cloud computing, the long-envisioned dream of computing as utility is achieved. Many of the current standalone cloud providers offer resources and services using pay-per-use fixed pricing. Spot pricing, recently introduced in Amazon EC2, is more efficient by setting the resource price dynamically, based on demand. However, this pricing scheme, similar to the uniform price auction, is truthful only when supply can be adjusted, such as the case of a standalone cloud provider. In a federated cloud, where resources from multiple cloud providers are integrated to increase elasticity and reliability, rational users can have a greater impact. In this paper, we evaluate the impact of rationality in a federated cloud, by comparing the consumer welfare achieved by spot pricing, currently used in Amazon EC2, and a strategy-proof pricing scheme. We consider different EC2 regions as providers in a federated cloud, and use traces of spot prices to determine the consumer requests and the user welfare. Our results show that spot pricing is not suitable in a federated cloud, where rational users can increase their welfare by being untruthful.","spot pricing, cloud computing, rationality, federated clouds","","CCGRID '12"
"Conference Paper","Al-Dulaimy A,Taheri J,Papadopoulos AV,Nolte T","LOOPS: A Holistic Control Approach for Resource Management in Cloud Computing","2021","117–124","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM/SPEC International Conference on Performance Engineering","Virtual Event, France","2021","9781450381949","https://doi.org/10.1145/3427921.3450254;http://dx.doi.org/10.1145/3427921.3450254","10.1145/3427921.3450254","In cloud computing model, resource sharing introduces major benefits for improving resource utilization and total cost of ownership, but it can create technical challenges on the running performance. In practice, orchestrators are required to allocate sufficient physical resources to each Virtual Machine (VM) to meet a set of predefined performance goals. To ensure a specific service level objective, the orchestrator needs to be equipped with a dynamic tool for assigning computing resources to each VM, based on the run-time state of the target environment. To this end, we present LOOPS, a multi-loop control approach, to allocate resources to VMs based on the service level agreement (SLA) requirements and the run-time conditions. LOOPS is mainly composed of one essential unit to monitor VMs, and three control levels to allocate resources to VMs based on requests from the essential node. A tailor-made controller is proposed with each level to regulate contention among collocated VMs, to reallocate resources if required, and to migrate VMs from one host to another. The three levels work together to meet the required SLA. The experimental results have shown that the proposed approach can meet applications' performance goals by assigning the resources required by cloud-based applications.","VM migration, resource management, cloud computing, vertical scaling, horizontal scaling, auto-scaling","","ICPE '21"
"Conference Paper","Chen S,Wang Y,Pedram M","Concurrent Placement, Capacity Provisioning, and Request Flow Control for a Distributed Cloud Infrastructure","2014","","European Design and Automation Association","Leuven, BEL","Proceedings of the Conference on Design, Automation & Test in Europe","Dresden, Germany","2014","9783981537024","","","Cloud computing and storage have attracted a lot of attention due to the ever increasing demand for reliable and cost-effective access to vast resources and services available on the Internet. Cloud services are typically hosted in a set of geographically distributed data centers, which we will call the cloud infrastructure. To minimize the total cost of ownership of this cloud infrastructure (which accounts for both the upfront capital cost and the operational cost of the infrastructure resources), the infrastructure owners/operators must do a careful planning of data center locations in the targeted service area (for example the US territories), data center capacity provisioning (i.e., the total CPU cycles per second that can be provided in each data center). In addition, they must have flow control policies that will distribute the incoming user requests to the available resources in the cloud infrastructure. This paper presents an approach for solving the unified problem of data center placement and provisioning, and request flow control in one shot. The solution technique is based on mathematical programming. Experimental results, using Google cluster data and placement/provisioning of up to eight data center sites demonstrate the cost savings of the proposed problem formulation and solution approach.","","","DATE '14"
"Conference Paper","Blocq G,Bachrach Y,Key P","The Shared Assignment Game and Applications to Pricing in Cloud Computing","2014","605–612","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems","Paris, France","2014","9781450327381","","","We propose an extension to the Assignment Game [37] in which sellers provide indivisible heterogeneous goods to their buyers. Each good takes up various amounts of resources and each seller has capacity constraints with respect to the total amount of resources it can provide. Hence, the total amount of goods that the seller can provide is dependent on the set of buyers. In this model, we first demonstrate that the core is empty and proceed to suggest a fair allocation of the resulting utility of an optimal match, using the Shapley value. We then examine scenarios where the worth and resource demands of each good are private information of selfish buyers and consider ways in which they can manipulate the system. We show that such Shapley value manipulations are bounded in terms of the gain an agent can achieve by using them. Finally, since this model can be of use when considering elastic resource allocation and utility sharing in cloud computing domains, we provide simulation results which show our approach maximizes welfare and, when used as a pricing scheme, can also increase the revenue of the cloud server providers over what is achieved with the widely-used fixed pricing scheme.","shapley value, cloud pricing, assignment game","","AAMAS '14"
"Conference Paper","Arabnejad V,Bubendorfer K,Ng B","Deadline Distribution Strategies for Scientific Workflow Scheduling in Commercial Clouds","2016","70–78","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Utility and Cloud Computing","Shanghai, China","2016","9781450346160","https://doi.org/10.1145/2996890.2996905;http://dx.doi.org/10.1145/2996890.2996905","10.1145/2996890.2996905","Commercial clouds have become a viable platform for performing a significant range of large scale scientific analyses - due to the offerings of elasticity, specialist hardware, software infrastructure and pay-as-you-go cost model. Such clouds represent a low upfront capital cost alternative to the use of dedicated eScience infrastructure. However, there are still significant technical hurdles associated with obtaining the best performance for the cost - it is easy to provision commercial clouds inefficiently resulting in great and potentially unanticipated expense.In this paper we introduce a new heuristic scheduling algorithm Deadline Distribution Ratio (DDR) to address the workflow scheduling problem with the objectives of minimizing the cost of Cloud computing resources while satisfying a given deadline. Within this context, we also investigate a range of different deadline distribution strategies and their effect on the overall scheduling performance. We then compare the DDR algorithm against three other published algorithms, using five different scientific workflows generated using the pegasus workflow generator, on a CloudSim simulation that implements a pricing model based on AWS. In general, the DDR algorithm returns the lowest costs across the majority of deadlines and workflows, while maintaining a high scheduling success rate.","cloud computing, scheduling, deadline distribution, scientific workflow","","UCC '16"
"Conference Paper","Henzinger TA,Singh AV,Singh V,Wies T,Zufferey D","A Marketplace for Cloud Resources","2010","1–8","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth ACM International Conference on Embedded Software","Scottsdale, Arizona, USA","2010","9781605589046","https://doi.org/10.1145/1879021.1879022;http://dx.doi.org/10.1145/1879021.1879022","10.1145/1879021.1879022","Cloud computing is an emerging paradigm aimed to offer users pay-per-use computing resources, while leaving the burden of managing the computing infrastructure to the cloud provider. We present a new programming and pricing model that gives the cloud user the flexibility of trading execution speed and price on a per-job basis. We discuss the scheduling and resource management challenges for the cloud provider that arise in the implementation of this model. We argue that techniques from real-time and embedded software can be useful in this context.","worst-case execution time, cloud computing, iaas, large-scale scheduling, pricing models","","EMSOFT '10"
"Conference Paper","Tirado JM,Higuero D,Isaila F,Carretero J","Predictive Data Grouping and Placement for Cloud-Based Elastic Server Infrastructures","2011","285–294","IEEE Computer Society","USA","Proceedings of the 2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","","2011","9780769543956","https://doi.org/10.1109/CCGrid.2011.49;http://dx.doi.org/10.1109/CCGrid.2011.49","10.1109/CCGrid.2011.49","Workload variations on Internet platforms such as YouTube, Flickr, LastFM require novel approaches to dynamic resource provisioning in order to meet QoS requirements, while reducing the Total Cost of Ownership (TCO) of the infrastructures. The economy of scale promise of cloud computing is a great opportunity to approach this problem, by developing elastic large scale server infrastructures. However, a proactive approach to dynamic resource provisioning requires prediction models forecasting future load patterns. On the other hand, unexpected volume and data spikes require reactive provisioning for serving unexpected surges in workloads. When workload can not be predicted, adequate data grouping and placement algorithms may facilitate agile scaling up and down of an infrastructure. In this paper, we analyze a dynamic workload of an on-line music portal and present an elastic Web infrastructure that adapts to workload variations by dynamically scaling up and down servers. The workload is predicted by an autoregressive model capturing trends and seasonal patterns. Further, for enhancing data locality, we propose a predictive data grouping based on the history of content access of a user community. Finally, in order to facilitate agile elasticity, we present a data placement based on workload and access pattern prediction. The experimental results demonstrate that our forecasting model predicts workload with a high precision. Further, the predictive data grouping and placement methods provide high locality, load balance and high utilization of resources, allowing a server infrastructure to scale up and down depending on workload.","elastic, prediction, cloud, data-grouping","","CCGRID '11"
"Conference Paper","Cavalcante E,Almeida A,Batista T,Cacho N,Lopes F,Delicato FC,Sena T,Pires PF","Exploiting Software Product Lines to Develop Cloud Computing Applications","2012","179–187","Association for Computing Machinery","New York, NY, USA","Proceedings of the 16th International Software Product Line Conference - Volume 2","Salvador, Brazil","2012","9781450310956","https://doi.org/10.1145/2364412.2364442;http://dx.doi.org/10.1145/2364412.2364442","10.1145/2364412.2364442","With the advance of the Cloud Computing paradigm, new challenges in terms of models, tools, and techniques to support developers to design, build and deploy complex software systems that make full use of the cloud technology arise. In the heterogeneous scenario of this new paradigm, the development of applications using cloud services becomes hard, and the software product lines (SPL) approach is potentially promising for this context since specificities of the cloud platforms, such as services heterogeneity, pricing model, and other aspects can be catered as variabilities to core features. In this perspective, this paper (i) proposes a seamless adaptation of the SPL-based development to include important features of cloud-based applications, and (ii) reports the experience of developing HW-CSPL, a SPL for the Health Watcher (HW) System, which allows citizens to register complaints and consult information regarding the public health system of a city. Several functionalities of this system were implemented using different Cloud Computing platforms, and run time specificities of this application deployed on the cloud were analyzed, as well as other information such as change impact and pricing.","health watcher system, cloud platforms, cloud computing, software product lines, services","","SPLC '12"
"Conference Paper","Wong P,He Z,Lo E","Parallel Analytics as a Service","2013","25–36","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data","New York, New York, USA","2013","9781450320375","https://doi.org/10.1145/2463676.2463714;http://dx.doi.org/10.1145/2463676.2463714","10.1145/2463676.2463714","Recently, massively parallel processing relational database systems (MPPDBs) have gained much momentum in the big data analytic market. With the advent of hosted cloud computing, we envision that the offering of MPPDB-as-a-Service (MPPDBaaS) will become attractive for companies having analytical tasks on only hundreds gigabytes to some ten terabytes of data because they can enjoy high-end parallel analytics at a cheap cost. This paper presents Thrifty, a prototype implementation of MPPDB-as-a-service. The major research issue is how to achieve a lower total cost of ownership by consolidating thousands of MPPDB tenants on to a shared hardware infrastructure, with a performance SLA that guarantees the tenants can obtain the query results as if they are executing their queries on dedicated machines. Thrifty achieves the goal by using a tenant-driven design that includes (1) a cluster design that carefully arranges the nodes in the cluster into groups and creates an MPPDB for each group of nodes, (2) a tenant placement that assigns each tenant to several MPPDBs (for high availability service through replication), and (3) a query routing algorithm that routes a tenant's query to the proper MPPDB at run-time. Experiments show that in a MPPDBaaS with 5000 tenants, where each tenant requests 2 to 32 nodes MPPDB to query against 200GB to 3.2TB of data, Thrifty can serve all the tenants with a 99.9% performance SLA guarantee and a high availability replication factor of 3, using only 18.7% of the nodes requested by the tenants.","cloud databases, multi-tenant databases, parallel databases, consolidation, database-as-a-service","","SIGMOD '13"
"Conference Paper","Kansal S,Singh G,Kumar H,Kaushal S","Pricing Models in Cloud Computing","2014","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2014 International Conference on Information and Communication Technology for Competitive Strategies","Udaipur, Rajasthan, India","2014","9781450332163","https://doi.org/10.1145/2677855.2677888;http://dx.doi.org/10.1145/2677855.2677888","10.1145/2677855.2677888","Cloud computing is one of the most promising computing models evolving from last decade in distributed computing. It has the capability of using services to allow the small Information Technology companies to rise in the market. With the growing use of cloud services number of companies has started entering in cloud market which includes cloud infrastructure providers. It has lead to the standardization of Application Programming Interfaces (API) and infrastructure. Optimal pricing of the services has become a major challenge for the cloud service providers. Various pricing models have evolved over the period. Some of these are the extended variants of Grid models whereas others completely new proposals. In this paper, various cloud service pricing issues along with recent models proposed in the literature have been reviewed. These models are classified into pay per use, subscription based and hybrid categories.","pricing model, static pricing, Cloud computing, dynamic pricing","","ICTCS '14"
"Conference Paper","Nguyen TA,Bimonte S,d'Orazio L,Darmont J","Cost Models for View Materialization in the Cloud","2012","47–54","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2012 Joint EDBT/ICDT Workshops","Berlin, Germany","2012","9781450311434","https://doi.org/10.1145/2320765.2320788;http://dx.doi.org/10.1145/2320765.2320788","10.1145/2320765.2320788","In classical databases, query performance is casually achieved through physical data structures such as caches, indexes and materialized views. In this context, many cost models help select a ""best set"" of such data structures. However, this selection task becomes more complex in the cloud. The criterion to optimize is indeed at least two-dimensional, with the monetary cost of using the cloud balancing query response time. Thus, we define in this paper new cost models that fit into the pay-as-you-go paradigm of cloud computing. These cost models help achieve a multi-criteria optimization of the view materialization vs. CPU power consumption problem, under budget constraints. Finally, we present experimental results that provide a first validation of our contribution and show that cloud view materialization is always desirable.","performance and cost optimization, cost models, materialized views, cloud computing","","EDBT-ICDT '12"
"Conference Paper","Henzinger TA,Singh AV,Singh V,Wies T,Zufferey D","Static Scheduling in Clouds","2011","1","USENIX Association","USA","Proceedings of the 3rd USENIX Conference on Hot Topics in Cloud Computing","Portland, OR","2011","","","","Cloud computing aims to give users virtually unlimited pay-per-use computing resources without the burden of managing the underlying infrastructure. We present a new job execution environment Flextic that exploits scalable static scheduling techniques to provide the user with a flexible pricing model, such as a tradeoff between different degrees of execution speed and execution price, and at the same time, reduce scheduling overhead for the cloud provider. We have evaluated a prototype of Flextic on Amazon EC2 and compared it against Hadoop. For various data parallel jobs from machine learning, image processing, and gene sequencing that we considered, Flextic has low scheduling overhead and reduces job duration by up to 15% compared to Hadoop, a dynamic cloud scheduler.","","","HotCloud'11"
"Conference Paper","Hong YJ,Xue J,Thottethodi M","Dynamic Server Provisioning to Minimize Cost in an IaaS Cloud","2011","147–148","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM SIGMETRICS Joint International Conference on Measurement and Modeling of Computer Systems","San Jose, California, USA","2011","9781450308144","https://doi.org/10.1145/1993744.1993799;http://dx.doi.org/10.1145/1993744.1993799","10.1145/1993744.1993799","Cloud computing holds the exciting potential of elastically scaling computation to match time-varying demand, thus eliminating the need to provision for peak demand to satisfy response-time requirements. Moreover, cloud vendors often offer several commitment levels for their machine instances (e.g., users can choose to pay an upfront premium for the discounted hourly usage price). Because cost is a major concern that may limit the cloud adoption, two key challenges are to determine (a) the number of machines to provision and (b) the commitment level at which the machine instances should be acquired, to minimize cost while satisfying response-time targets. This paper address the above two challenges in an Infrastructure-as-a-Service (IaaS) cloud. Our simulations with real Web server load traces reveal that our techniques offer a cost reduction between 13% and 29% (21% on average) under Amazon EC2 pricing models.","cloud computing, capacity planning, dynamic provisioning","","SIGMETRICS '11"
"Conference Paper","Uriarte RB,Tiezzi F,Nicola R","SLAC: A Formal Service-Level-Agreement Language for Cloud Computing","2014","419–426","IEEE Computer Society","USA","Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing","","2014","9781479978816","https://doi.org/10.1109/UCC.2014.53;http://dx.doi.org/10.1109/UCC.2014.53","10.1109/UCC.2014.53","The need of mechanisms to automate and regulate the interaction amongst the parties involved in the offered cloud services is exacerbated by the increasing number of providers and solutions that enable the cloud paradigm. This regulation needs to be defined through a contract, the so-called Service Level Agreement (SLA). We argue that the current solutions for SLA specification cannot cope with the distinctive characteristics of clouds. Therefore, in this paper we define a language, named SLAC, devised for specifying SLA for the cloud computing domain. The main differences with respect to the existing specification languages are: SLAC is domain specific, its semantics are formally defined in order to avoid ambiguity, it supports the main cloud deployment models, and it enables the specification of multi-party agreements. Moreover, SLAC supports the business aspects of the domain, such as pricing schemes, business actions and metrics. Furthermore, SLAC comes with an open-source software framework which enables the specification, evaluation and enforcement of SLAs for clouds. We illustrate potentialities and effectiveness of the SLAC language and its management framework by experimenting with an Open Nebula cloud system.","Constraint satisfaction problems, Formal Languages, Service Level Agreement, Cloud Computing","","UCC '14"
"Conference Paper","Nodari A,Nurminen JK,Frühwirth C","Inventory Theory Applied to Cost Optimization in Cloud Computing","2016","470–473","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st Annual ACM Symposium on Applied Computing","Pisa, Italy","2016","9781450337397","https://doi.org/10.1145/2851613.2851869;http://dx.doi.org/10.1145/2851613.2851869","10.1145/2851613.2851869","Cloud computing providers offer two different pricing schemes when renting virtual machines: reserved instances and on-demand instances. On-demand instances are paid only when utilized and they are useful to satisfy a fluctuating demand. Conversely, reserved instances are paid for a certain time period and are independent of usage. Since reserved instances require more commitment from users, they are cheaper than on-demand instances. However, in order to be cost-effective compared to on-demand instances, they have to be extensively utilized. This work focuses on finding the optimal combination of on-demand and reserved instances, such that the demand is satisfied and the costs minimized. To achieve this goal, this study introduces a stochastic model of the resources, based on Inventory Theory. The idea is to formulate the optimization problem as an inventory-keeping problem and then derive the optimal strategy. The paper evaluates the proposed model using data from an industry case, comparing the performance with a brute-force approach. The conducted experiments show that the Inventory Theory model provides accurate results and potentially allows prior research on Inventory Theory to be applied to optimal cloud provisioning.","cloud provisioning, cost optimization, resource allocation, inventory theory","","SAC '16"
"Conference Paper","Farokhi S","Towards an SLA-Based Service Allocation in Multi-Cloud Environments","2014","591–594","IEEE Press","Chicago, Illinois","Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing","","2014","9781479927838","https://doi.org/10.1109/CCGrid.2014.62;http://dx.doi.org/10.1109/CCGrid.2014.62","10.1109/CCGrid.2014.62","Cloud computing popularity is growing rapidly and consequently the number of companies offering their services in the form of Software-as-a-Service (SaaS) or Infrastructure-as-a-Service (IaaS) is increasing. The diversity and usage benefits of the IaaS offers are encouraging SaaS providers to lease resources from the Cloud instead of operating their own data centers. This helps them to get rid of the maintenance overheads and better satisfy their customers which are more demanding in terms of service requirements nowadays. Such evolutionary tendency is leading to the emergence of new ways of service provisioning in which relying on infrastructure services of a single Cloud provider is not sufficient. Namely, the need of using Cloud services from multiple Clouds with various quality attributes and pricing models has been raised recently. Although service allocation based on Service Level Agreement (SLA) has been well investigated in Cloud computing so far, the new upcoming issues regarding to utilize multiple Clouds has led to new challenges. This paper looks at the service selection and allocation in a Multi-Cloud, as a delivery model of multiple Clouds, from the perspective of SaaS provider. The proposed framework assists SaaS providers to find suitable infrastructure services which best satisfy their requirements while handling SLA issues. We present an overview of the complete system and discus how the services are selected and the corresponding SLAs are monitored to detect the SLA violations.","InterCloud-SLA, service allocation, service level agreement (SLA), infrastructure-as-a-service (IaaS), software-as-a-service (SaaS), cloud computing, service selection, multi-cloud","","CCGRID '14"
"Conference Paper","Mihailescu M,Teo YM","On Economic and Computational-Efficient Resource Pricing in Large Distributed Systems","2010","838–843","IEEE Computer Society","USA","Proceedings of the 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing","","2010","9780769540399","https://doi.org/10.1109/CCGRID.2010.124;http://dx.doi.org/10.1109/CCGRID.2010.124","10.1109/CCGRID.2010.124","There is growing interest in large-scale systems where globally distributed and commoditized resources can be shared and traded, such as peer-to-peer networks, grids, and cloud computing. Users of these systems are rational and maximize their own interest when consuming and contributing shared resources, even if by doing so they affect the overall efficiency of the system. To manage rational users, resource pricing and allocation can provide the necessary incentives for users to behave such that the overall efficiency can be maximized. In this paper, we propose a dynamic pricing mechanism for the allocation of shared resources, and evaluate its performance. In contrast with several existing trading models, our scheme is designed to allocate a request with multiple resource types, such that the user does not have to aggregate different resource types manually. We formally prove the economic properties of our pricing scheme using the mechanism design framework. We perform both theoretical and simulation analysis to evaluate the economic and computational efficiency of the allocation and the scalability of the mechanism. Our simulations are validated against a prototype implementation on PlanetLab.","","","CCGRID '10"
"Conference Paper","Ge Y,Zhang Y,Qiu Q,Lu YH","A Game Theoretic Resource Allocation for Overall Energy Minimization in Mobile Cloud Computing System","2012","279–284","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2012 ACM/IEEE International Symposium on Low Power Electronics and Design","Redondo Beach, California, USA","2012","9781450312493","https://doi.org/10.1145/2333660.2333724;http://dx.doi.org/10.1145/2333660.2333724","10.1145/2333660.2333724","Cloud computing and virtualization techniques provide mobile devices with battery energy saving opportunities by allowing them to offload computation and execute code remotely. When the cloud infrastructure consists of heterogeneous servers, the mapping between mobile devices and servers plays an important role in determining the energy dissipation on both sides. From an environmental impact perspective, any energy dissipation related to computation should be counted. To achieve energy sustainability, it is important reducing the overall energy consumption of the mobile systems and the cloud infrastructure. Furthermore, reducing cloud energy consumption can potentially reduce the cost of mobile cloud users because the pricing model of cloud services is pay-by-usage. In this paper, we propose a game-theoretic approach to optimize the overall energy in a mobile cloud computing system. We formulate the energy minimization problem as a congestion game, where each mobile device is a player and his strategy is to select one of the servers to offload the computation while minimizing the overall energy consumption. We prove that the Nash equilibrium always exists in this game and propose an efficient algorithm that could achieve the Nash equilibrium in polynomial time. Experimental results show that our approach is able to reduce the total energy of mobile devices and servers compared to a random approach and an approach which only tries to reduce mobile devices alone.","congestion game, game theory, virtualization, power management, mobile cloud computing","","ISLPED '12"
"Conference Paper","Imai S,Patterson S,Varela CA","Cost-Efficient Elastic Stream Processing Using Application-Agnostic Performance Prediction","2016","604–607","IEEE Press","Cartagena, Columbia","Proceedings of the 16th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing","","2016","9781509024520","https://doi.org/10.1109/CCGrid.2016.89;http://dx.doi.org/10.1109/CCGrid.2016.89","10.1109/CCGrid.2016.89","Cloud computing adds great on-demand scalability to stream processing systems with its pay-per-use cost model. However, to promise service level agreements to users while keeping resource allocation cost low is a challenging task due to uncertainties coming from various sources, such as the target application's scalability, future computational demand, and the target cloud infrastructure's performance variability. To deal with these uncertainties, it is essential to create accurate application performance prediction models. In cloud computing, the current state of the art in performance modelling remains application-specific. We propose an application-agnostic performance modeling that is applicable to a wide range of applications. We also propose an extension to probabilistic performance prediction. This paper reports the progress we have made so far.","cloud computing, performance prediction, resource allocation","","CCGRID '16"
"Conference Paper","Al-Shishtawy A,Vlassov V","ElastMan: Autonomic Elasticity Manager for Cloud-Based Key-Value Stores","2018","115–116","Association for Computing Machinery","New York, NY, USA","Proceedings of the 22nd International Symposium on High-Performance Parallel and Distributed Computing","New York, New York, USA","2018","9781450319102","https://doi.org/10.1145/2462902.2462925;http://dx.doi.org/10.1145/2462902.2462925","10.1145/2462902.2462925","The increasing spread of elastic Cloud services, together with the pay-as-you-go pricing model of Cloud computing, has led to the need of an elasticity controller. The controller automatically resizes an elastic service in response to changes in workload, in order to meet Service Level Objectives (SLOs) at a reduced cost. However, variable performance of Cloud virtual machines and nonlinearities in Cloud services complicates the controller design. We present the design and evaluation of ElastMan, an elasticity controller for Cloud-based elastic key-value stores. ElastMan combines feedforward and feedback control. Feedforward control is used to respond to spikes in the workload by quickly resizing the service to meet SLOs at a minimal cost. Feedback control is used to correct modeling errors and to handle diurnal workload. We have implemented and evaluated ElastMan using the Voldemort key-value store running in a Cloud environment based on OpenStack. Our evaluation shows the feasibility and effectiveness of our approach to automation of Cloud service elasticity.","elasticity controller, cloud computing, key-value store","","HPDC '13"
"Conference Paper","Mian R,Martin P,Zulkernine F,Vazquez-Poletti JL","Estimating Resource Costs of Data-Intensive Workloads in Public Clouds","2012","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 10th International Workshop on Middleware for Grids, Clouds and e-Science","Montreal, Quebec, Canada","2012","9781450316088","https://doi.org/10.1145/2405136.2405139;http://dx.doi.org/10.1145/2405136.2405139","10.1145/2405136.2405139","The promise of ""infinite"" resources given by the cloud computing paradigm has led to recent interest in exploiting clouds for large-scale data-intensive computing. In this paper, we present a model to estimate the resource costs for executing data-intensive workloads in a public cloud. The cost model quantifies the cost-effectiveness of a resource configuration for a given workload with consumer performance requirements expressed as SLAs, and is a key component of a larger framework for resource provisioning in clouds. We instantiate the cost model for the Amazon cloud, and experimentally evaluate the impact of key factors on the accuracy of the model.","cost model, resource provisioning, cloud computing","","MGC '12"
"Conference Paper","Al-Shishtawy A,Vlassov V","ElastMan: Autonomic Elasticity Manager for Cloud-Based Key-Value Stores","2013","115–116","Association for Computing Machinery","New York, NY, USA","Proceedings of the 22nd International Symposium on High-Performance Parallel and Distributed Computing","New York, New York, USA","2013","9781450319102","https://doi.org/10.1145/2493123.2462925;http://dx.doi.org/10.1145/2493123.2462925","10.1145/2493123.2462925","The increasing spread of elastic Cloud services, together with the pay-as-you-go pricing model of Cloud computing, has led to the need of an elasticity controller. The controller automatically resizes an elastic service in response to changes in workload, in order to meet Service Level Objectives (SLOs) at a reduced cost. However, variable performance of Cloud virtual machines and nonlinearities in Cloud services complicates the controller design. We present the design and evaluation of ElastMan, an elasticity controller for Cloud-based elastic key-value stores. ElastMan combines feedforward and feedback control. Feedforward control is used to respond to spikes in the workload by quickly resizing the service to meet SLOs at a minimal cost. Feedback control is used to correct modeling errors and to handle diurnal workload. We have implemented and evaluated ElastMan using the Voldemort key-value store running in a Cloud environment based on OpenStack. Our evaluation shows the feasibility and effectiveness of our approach to automation of Cloud service elasticity.","key-value store, cloud computing, elasticity controller","","HPDC '13"
"Conference Paper","An B,Lesser V,Irwin D,Zink M","Automated Negotiation with Decommitment for Dynamic Resource Allocation in Cloud Computing","2010","981–988","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: Volume 1 - Volume 1","Toronto, Canada","2010","9780982657119","","","We consider the problem of allocating networked resources in dynamic environment, such as cloud computing platforms, where providers strategically price resources to maximize their utility. Resource allocation in these environments, where both providers and consumers are selfish agents, presents numerous challenges since the number of consumers and their resource demand is highly dynamic. While numerous auction-based approaches have been proposed in the literature, this paper explores an alternative approach where providers and consumers automatically negotiate resource leasing contracts. Since resource demand and supply can be dynamic and uncertain, we propose a distributed negotiation mechanism where agents negotiate over both a contract price and a decommitment penalty, which allows agents to decommit from contracts at a cost. We compare our approach experimentally, using representative scenarios and workloads, to both combinatorial auctions and the fixed-price model used by Amazon's Elastic Compute Cloud, and show that the negotiation model achieves a higher social welfare.","cloud computing, negotiation strategy, automated negotiation","","AAMAS '10"
"Conference Paper","Li Z,Wu G","Optimizing VM Live Migration Strategy Based on Migration Time Cost Modeling","2016","99–109","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems","Santa Clara, California, USA","2016","9781450341837","https://doi.org/10.1145/2881025.2881035;http://dx.doi.org/10.1145/2881025.2881035","10.1145/2881025.2881035","The live migration technology of virtual machine is very helpful for dynamic workload balance, server consolidation and fault tolerance in cloud computing environment. It is important to build live migration strategies which lead to low migration time, thus helping reduce migration cost while achieving migration goal. So we look into the topic of building a model to quantitatively predict live migration time. We thoroughly analyze the key parameters that affect the migration time and construct a live migration time cost model based on KVM. The evaluation of time cost model shows that the average prediction accuracy is above 90% in comparison with measured time. Based on time cost model, we propose 2 optimized live migration strategies for different application scenarios, one for load balance and fault tolerance, the other for server consolidation. The evaluation shows our optimized migration strategies can save 35% 50% of cost compared to the random migration strategy. We believe this should be the first comprehensive study of optimizing live migration strategy with migration time cost as a key factor.","live migration, time cost model, migration strategy","","ANCS '16"
"Conference Paper","Kang DK,Kim SH,Youn CH,Chen M","Cost Adaptive Workflow Scheduling in Cloud Computing","2014","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 8th International Conference on Ubiquitous Information Management and Communication","Siem Reap, Cambodia","2014","9781450326445","https://doi.org/10.1145/2557977.2558079;http://dx.doi.org/10.1145/2557977.2558079","10.1145/2557977.2558079","In cloud computing, it remains a challenge to allocate virtualized resource with financial cost minimization and acceptable Quality of Service assurance. In general, the VM instance is allocated to cloud service users based on not actual job processing time but the fixed resource allocation time predetermined by cloud pricing policy in contrast to grid environment. In this case, the unnecessary cost dissipation is occurred by the wasted partial instance hours of allocated resource. To address this problem, we propose the heuristic based workflow scheduling scheme considering cloud-pricing model in this paper. Our scheme is composed of two phases: VM packing and MRSR (Multi Requests to Single Resource) phases. In VM-packing phase, preassigned multi tasks are aggregated into the common VM instance sequentially, and these tasks are merged in parallel by MRSR phase. By using our proposed schemes, we are able to reduce the number of required VM instances and achieve the significant cost saving while we guarantee the user's SLA (Service Level Agreement) in terms of workflow deadline. Our proposed schemes cannot only reduce the cost by 30% compared to traditional workflow scheduling schemes but also assure user's SLA.","cloud resource management, workflow scheduling, virtual machine allocation","","ICUIMC '14"
"Conference Paper","Gmach D,Rolia J,Cherkasova L","Selling T-Shirts and Time Shares in the Cloud","2012","539–546","IEEE Computer Society","USA","Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (Ccgrid 2012)","","2012","9780769546919","https://doi.org/10.1109/CCGrid.2012.68;http://dx.doi.org/10.1109/CCGrid.2012.68","10.1109/CCGrid.2012.68","Cloud computing has emerged as a new and alternative approach for providing computing services. Customers acquire and release resources by requesting and returning virtual machines to the cloud. Different service models and pricing schemes are offered by cloud service providers. This can make it difficult for customers to compare cloud services and select an appropriate solution. Cloud Infrastructure-as-a-Service vendors offer a t-shirt approach for Virtual Machines (VMs) on demand. Customers can select from a set of fixed size VMs and vary the number of VMs as their demands change. Private clouds often offer another alternative, called time-sharing, where the capacity of each VM is permitted to change dynamically. With this approach each virtual machine is allocated a dynamic amount of CPU and memory resources over time to better utilize available resources. We present a tool that can help customers make informed decisions about which approach works most efficiently for their workloads in aggregate and for each workload separately. A case study using data from an enterprise customer with 312 workloads demonstrates the use of the tool. It shows that for the given set of workloads the t-shirt model requires almost twice the number of physical servers as the time share model. The costs for such infrastructure must ultimately be passed on to the customer in terms of monetary costs or performance risks. We conclude that private and public clouds should consider offering both resource sharing models to meet the needs of customers.","resource sharing, virtual machine sizing, cloud service models, virtualization, data center efficiency","","CCGRID '12"
"Conference Paper","Al-Shishtawy A,Vlassov V","ElastMan: Elasticity Manager for Elastic Key-Value Stores in the Cloud","2013","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2013 ACM Cloud and Autonomic Computing Conference","Miami, Florida, USA","2013","9781450321723","https://doi.org/10.1145/2494621.2494630;http://dx.doi.org/10.1145/2494621.2494630","10.1145/2494621.2494630","The increasing spread of elastic Cloud services, together with the pay-as-you-go pricing model of Cloud computing, has led to the need of an elasticity controller. The controller automatically resizes an elastic service in response to changes in workload, in order to meet Service Level Objectives (SLOs) at a reduced cost. However, variable performance of Cloud Virtual Machines and nonlinearities in Cloud services, such as the diminishing reward of adding a service instance with increasing the scale, complicates the controller design. We present the design and evaluation of ElastMan, an elasticity controller for Cloud-based elastic key-value stores. ElastMan combines feedforward and feedback control. Feedforward control is used to respond to spikes in the workload by quickly resizing the service to meet SLOs at a minimal cost. Feedback control is used to correct modeling errors and to handle diurnal workload. To address nonlinearities, our design of ElastMan leverages the near-linear scalability of elastic Cloud services in order to build a scale-independent model of the service. We have implemented and evaluated ElastMan using the Voldemort key-value store running in an OpenStack Cloud environment. Our evaluation shows the feasibility and effectiveness of our approach to automation of Cloud service elasticity.","feedforward control, SLO, cloud computing, elasticity controller, feedback control, cloud storage","","CAC '13"
"Conference Paper","Karatza H","Large Scale Real-Time Distributed Systems – Resource Allocation and Scheduling Issues","2021","","Association for Computing Machinery","New York, NY, USA","7th Conference on the Engineering of Computer Based Systems","Novi Sad, Serbia","2021","9781450390576","https://doi.org/10.1145/3459960.3461561;http://dx.doi.org/10.1145/3459960.3461561","10.1145/3459960.3461561","Due to the advances in networks and computing systems, many aspects of our daily life depend on distributed interconnected computing resources. Large-scale distributed systems offer computational services to scientists, consumers and enterprises. Efficient management of distributed resources is crucial to use effectively the power of these systems and achieve good performance. Large-scale distributed systems are usually real-time as they are used for serving applications which require real-time processing. It is essential that appropriate resource allocation and scheduling techniques are utilized ensuring timeliness. Cloud computing, as a large-scale distributed computing paradigm based on a pay-as-you-go pricing model, has been extensively used for the deployment of complex computationally intensive applications. Particularly important in cloud computing is to run delay-sensitive applications. This can be achieved due to cloud’s high-performance computing capabilities for real-time execution. However, approaches to resolve other issues such as cost and energy conservation are necessary. In the last years, there is an expansion of the Internet of Things (IoT). There is a plethora of IoT applications which generate huge amounts of data and it is important to process these data in real-time and provide fast decisions. As a result, fog computing has emerged as a computing model which extends the cloud to the edge of the network, thus reducing the latency of IoT data transmission. The computational capacity of fog resources is usually limited, therefore it is necessary to employ algorithms that involve the collaboration between the cloud and fog resources. Consequently, appropriate scheduling of time-sensitive applications is required to exploit the capacity of cloud and fog computing so that the workload’s deadlines are met. In this keynote, we will present and discuss various aspects of large-scale real-time distributed systems, from the perspective of resource allocation and scheduling and we will conclude with future directions in this research area.","scheduling, large-scale distributed systems, real-time systems","","ECBS 2021"
"Conference Paper","Georgoulakis Misegiannis M,Kantere Vverena,d'Orazio L","Multi-Objective Query Optimization in Spark SQL","2022","70–74","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th International Database Engineered Applications Symposium","Budapest, Hungary","2022","9781450397094","https://doi.org/10.1145/3548785.3548800;http://dx.doi.org/10.1145/3548785.3548800","10.1145/3548785.3548800","Query optimization is a challenging process of DBMSs. When tackling query optimization in the cloud, there exists a simultaneous need of providing an optimal physical query execution plan, as well as an optimal resource configuration among available ones. Cloud computing features like resource elasticity and pricing make the process of finding this optimal query plan a multi-objective problem, with the monetary cost being an equally important factor to query execution time. Apache Spark is a popular choice for managing big data in the cloud. However, query optimization in its SQL module (Spark SQL) involves a number of limitations due to the rule-based nature of its optimizer, Catalyst. We propose a multi-objective cost model for the extension of the query optimizer of Apache Spark, aiming to minimize both objectives of query execution time and monetary cost, as well as a methodology for exploring the space of Pareto-optimal query plans and selecting one. The cost model is implemented and tuned, and an experimental study is conducted to validate its accuracy.","Catalyst optimizer, multi-objective optimization, query optimization, cloud computing, cost model, Apache Spark","","IDEAS '22"
"Conference Paper","Kaulakienundefined D,Thomsen C,Pedersen TB,Çetintemel U,Kraska T","SpotADAPT: Spot-Aware (Re-)Deployment of Analytical Processing Tasks on Amazon EC2","2015","59–68","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Eighteenth International Workshop on Data Warehousing and OLAP","Melbourne, Australia","2015","9781450337854","https://doi.org/10.1145/2811222.2811227;http://dx.doi.org/10.1145/2811222.2811227","10.1145/2811222.2811227","Having constantly increasing amounts of data, the analysis of it is often entrusted for a MapReduce framework. The execution of an analytical workload can be cheapened by adopting cloud computing resources, and in particular by using spot instances (cheap, fluctuating price instances) offered by Amazon Web Services (AWS). The users aiming for the spot market are presented with many instance types placed in multiple datacenters in the world, and thus it is difficult to choose the optimal deployment. In this paper, we propose the framework SpotADAPT (Spot-Aware (re-)Deployment of Analytical Processing Tasks) which is designed to help users by first, estimating the workload execution time on different AWS instance types, and, second, proposing the deployment (i.e., specific availability zone, instance type, pricing model) aligned with user-provided optimization goals (fastest or cheapest execution within boundaries). Moreover, during the execution of the workload, SpotADAPT suggests a redeployment if the current spot instance gets terminated by Amazon or a better deployment becomes possible due to fluctuations of the spot prices. The approach is evaluated using the actual execution times of typical analytical workloads and real spot price traces. SpotADAPT's suggested deployments are comparable to the theoretically optimal ones, and in particular, it shows good cost benefits for the budget optimization - on average SpotADAPT is at most 0.3% more expensive than the theoretically optimal deployments.","execution time estimation, ec2, spot instances, amazon web services, hadoop","","DOLAP '15"
"Conference Paper","Chen J,Wang C,Zhou BB,Sun L,Lee YC,Zomaya AY","Tradeoffs Between Profit and Customer Satisfaction for Service Provisioning in the Cloud","2011","229–238","Association for Computing Machinery","New York, NY, USA","Proceedings of the 20th International Symposium on High Performance Distributed Computing","San Jose, California, USA","2011","9781450305525","https://doi.org/10.1145/1996130.1996161;http://dx.doi.org/10.1145/1996130.1996161","10.1145/1996130.1996161","The recent cloud computing paradigm represents a trend of moving business applications to platforms run by parties located in different administrative domains. A cloud platform is often highly scalable and cost-effective through its pay-as-you-go pricing model. However, being shared by a large number of users, the running of applications in the platform faces higher performance uncertainty compared to a dedicated platform. Existing Service Level Agreements (SLAs) cannot sufficiently address the performance variation issue. In this paper, we use utility theory leveraged from economics and develop a new utility model for measuring customer satisfaction in the cloud. Based on the utility model, we design a mechanism to support utility-based SLAs in order to balance the performance of applications and the cost of running them. We consider an infrastructure-as-a-service type cloud platform (e.g., Amazon EC2), where a business service provider leases virtual machine (VM) instances with spot prices from the cloud and gains revenue by serving its customers. Particularly, we investigate the interaction of service profit and customer satisfaction. In addition, we present two scheduling algorithms that can effectively bid for different types of VM instances to make tradeoffs between profit and customer satisfaction. We conduct extensive simulations based on the performance data of different types of Amazon EC2 instances and their price history. Our experimental results demonstrate that the algorithms perform well across the metrics of profit, customer satisfaction and instance utilization.","service level agreement, scheduling, customer satisfaction, utility theory","","HPDC '11"
"Conference Paper","Besbes O,Elmachtoub AN,Sun Y","Static Pricing: Universal Guarantees for Reusable Resources","2019","393–394","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2019 ACM Conference on Economics and Computation","Phoenix, AZ, USA","2019","9781450367929","https://doi.org/10.1145/3328526.3329585;http://dx.doi.org/10.1145/3328526.3329585","10.1145/3328526.3329585","We consider a fundamental pricing model in which a fixed number of units of a reusable resource are used to serve customers. Customers arrive to the system according to a stochastic process and upon arrival decide whether or not to purchase the service, depending on their willingness-to-pay and the current price. The service time during which the resource is used by the customer is stochastic and the firm may incur a service cost. This model represents various markets for reusable resources such as cloud computing, shared vehicles, rotable parts, and hotel rooms. In the present paper, we analyze this pricing problem when the firm attempts to maximize a weighted combination of three central metrics: profit, market share, and service level. Under Poisson arrivals, exponential service times, and standard assumptions on the willingness-to-pay distribution, we establish a series of results that characterize the performance of static pricing in such environments. In particular, while an optimal policy is fully dynamic in such a context, we prove that a static pricing policy simultaneously guarantees 78.9% of the profit, market share, and service level from the optimal policy. Notably, this result holds for any service rate and number of units the firm operates. In the special case where there are two units and the induced demand is linear, we also prove that the static policy guarantees 95.5% of the profit from the optimal policy. Our numerical findings on a large testbed of instances suggest that the latter result is quite indicative of the profit obtained by the static pricing policy across all parameters.","static pricing, reusable resources, dynamic pricing","","EC '19"
"Conference Paper","Mathew A,Andrikopoulos V,Blaauw FJ","Exploring the Cost and Performance Benefits of AWS Step Functions Using a Data Processing Pipeline","2021","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing","Leicester, United Kingdom","2021","9781450385640","https://doi.org/10.1145/3468737.3494084;http://dx.doi.org/10.1145/3468737.3494084","10.1145/3468737.3494084","In traditional cloud computing, dedicated hardware is substituted by dynamically allocated, utility-oriented resources such as virtualized servers. While cloud services are following the pay-as-you-go pricing model, resources are billed based on instance allocation and not on the actual usage, leading the customers to be charged needlessly. In serverless computing, as exemplified by the Function-as-a-Service (FaaS) model where functions are the basic resources, functions are typically not allocated or charged until invoked or triggered. Functions are not applications, however, and to build compelling serverless applications they frequently need to be orchestrated with some kind of application logic. A major issue emerging by the use of orchestration is that it complicates further the already complex billing model used by FaaS providers, which in combination with the lack of granular billing and execution details offered by the providers makes the development and evaluation of serverless applications challenging.Towards shedding some light into this matter, in this work we extensively evaluate the state-of-the-art function orchestrator AWS Step Functions (ASF) with respect to its performance and cost. For this purpose we conduct a series of experiments using a serverless data processing pipeline application developed as both ASF Standard and Express workflows. Our results show that Step Functions using Express workflows are economical when running short-lived tasks with many state transitions. In contrast, Standard workflows are better suited for long-running tasks, offering in addition detailed debugging and logging information. However, even if the behavior of the orchestrated AWS Lambda functions influences both types of workflows, Step Functions realized as Express workflows get impacted the most by the phenomena affecting Lambda functions.","serverless performance, AWS step functions, AWS lambda, function-as-a-service (FaaS), serverless, serverless cost","","UCC '21"
"Book","","CloudDB '10: Proceedings of the Second International Workshop on Cloud Data Management","2010","","Association for Computing Machinery","New York, NY, USA","","Toronto, ON, Canada","2010","9781450303804","","","It is our great pleasure to welcome you to the Second International Workshop on Cloud Data Management (CloudDB 2010). Cloud computing is set to revolutionize the IT industry, and database services are at the core of cloud computing since most information systems are built on database services. Cloud data management holds many promises and challenges. CloudDB 2010 is intended to address the challenges of large-scale data management based on cloud computing infrastructure. This workshop brings together researchers and practitioners in cloud computing and data-intensive system designs, parallel algorithms, data management, scientific applications, and information-based applications to maximize performance, minimize cost and improve the scale of their endeavors.This workshop attracted 11 submissions from Asia, Europe, and North America. Due to the high quality of the submissions received, the program committee decided to accept 8 full papers. These papers cover a variety of topics, including cloud data security, cloud data management and cloud system applications. We hope that they will serve as a valuable starting point for much brilliant thinking in cloud data management.Paper ""Towards a Data-centric View of Cloud Security"" discusses data management challenges in the areas of secure distributed query processing, system analysis and forensics, and query correctness assurance. Zhou et al. proposed a data-centric view of cloud security.Paper ""ESQP: An Efficient SQL Query Processing for Cloud Data Management"" by Zhao et al. proposed an efficient algorithm about query processing on structured data. They also demonstrated the efficiency and scalability of the algorithm with kinds of experiments.In the paper ""Benchmarking Cloud-based Data Management Systems"", Shi et al. conducted comprehensive experiments on several representative cloud-based data management systems to explore relative performance of different implementation approaches. In the paper ""Towards Bipartite Graph Data Management"", Zhao et al. fully studied the BGDM and developed a logic graph structure for indexing bipartite graphs to improve common operations efficiently.In ""Contract-based Cloud Architecture"", Alnemr et al. studied several issues such as security and legality that should be considered before entering the cloud. They showed that companies have to comply with diverse laws across jurisdictions and are accountable to various national regulators. Security requirements may not be compatible with those offered by existing providers.In the paper ""Comparing SQL and MapReduce to Compute Naive Bayes in a Single Table Scan"", Ordonez et al. presented some novel techniques to handle the data mining which is performed on flat files inside the DBMS, and considered two phases of the classifier: building the model and scoring a new data set.In the paper ""Adaptive Query Execution for Data Management in the Cloud"", Popescu et al. focused on analyzing the ""light"" queries processed on the cloud by using an adaptive scheme, which uses a cost model to switch between MapReduce and a DBMS.In the paper ""Dynamic Data Replication through Virtualization"", Daudjee et al. investigated data replication in a virtualized environment, focused on how to provision services when the master database server is heavily loaded or when it fails.","","Proceedings",""
