@article{10.1145/2663492,
author = {Chau, Chi-Kin and Wang, Qian and Chiu, Dah-Ming},
title = {Economic Viability of Paris Metro Pricing for Digital Services},
year = {2014},
issue_date = {October 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2–3},
issn = {1533-5399},
url = {https://doi.org/10.1145/2663492},
doi = {10.1145/2663492},
abstract = {Nowadays digital services, such as cloud computing and network access services, allow dynamic resource allocation and virtual resource isolation. This trend can create a new paradigm of flexible pricing schemes. A simple pricing scheme is to allocate multiple isolated service classes with differentiated prices, namely Paris Metro Pricing (PMP). The benefits of PMP are its simplicity and applicability to a wide variety of general digital services, without considering specific performance guarantees for different service classes. The central issue of our study is whether PMP is economically viable, namely whether it will produce more profit for the service provider and whether it will achieve more social welfare. Prior studies had only considered specific models and arrived at conflicting conclusions. In this article, we identify unifying principles in a general setting and derive general sufficient conditions that can guarantee the viability of PMP. We further apply the results to analyze various examples of digital services.},
journal = {ACM Trans. Internet Technol.},
month = {oct},
articleno = {12},
numpages = {21},
keywords = {cloud computing services, service classes, Internet economics, pricing}
}

@article{10.1145/2815624,
author = {Poola, Deepak and Ramamohanarao, Kotagiri and Buyya, Rajkumar},
title = {Enhancing Reliability of Workflow Execution Using Task Replication and Spot Instances},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1556-4665},
url = {https://doi.org/10.1145/2815624},
doi = {10.1145/2815624},
abstract = {Cloud environments offer low-cost computing resources as a subscription-based service. These resources are elastically scalable and dynamically provisioned. Furthermore, cloud providers have also pioneered new pricing models like spot instances that are cost-effective. As a result, scientific workflows are increasingly adopting cloud computing. However, spot instances are terminated when the market price exceeds the users bid price. Likewise, cloud is not a utopian environment. Failures are inevitable in such large complex distributed systems. It is also well studied that cloud resources experience fluctuations in the delivered performance. These challenges make fault tolerance an important criterion in workflow scheduling. This article presents an adaptive, just-in-time scheduling algorithm for scientific workflows. This algorithm judiciously uses both spot and on-demand instances to reduce cost and provide fault tolerance. The proposed scheduling algorithm also consolidates resources to further minimize execution time and cost. Extensive simulations show that the proposed heuristics are fault tolerant and are effective, especially under short deadlines, providing robust schedules with minimal makespan and cost.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {feb},
articleno = {30},
numpages = {21},
keywords = {Fault tolerance, scheduling, task duplication, task retry, cloud, spot instances, workflows}
}

@article{10.1145/3041036,
author = {Rodriguez, Maria A. and Buyya, Rajkumar},
title = {Budget-Driven Scheduling of Scientific Workflows in IaaS Clouds with Fine-Grained Billing Periods},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1556-4665},
url = {https://doi.org/10.1145/3041036},
doi = {10.1145/3041036},
abstract = {With the advent of cloud computing and the availability of data collected from increasingly powerful scientific instruments, workflows have become a prevailing mean to achieve significant scientific advances at an increased pace. Scheduling algorithms are crucial in enabling the efficient automation of these large-scale workflows, and considerable effort has been made to develop novel heuristics tailored for the cloud resource model. The majority of these algorithms focus on coarse-grained billing periods that are much larger than the average execution time of individual tasks. Instead, our work focuses on emerging finer-grained pricing schemes (e.g., per-minute billing) that provide users with more flexibility and the ability to reduce the inherent wastage that results from coarser-grained ones. We propose a scheduling algorithm whose objective is to optimize a workflow’s execution time under a budget constraint; quality of service requirement that has been overlooked in favor of optimizing cost under a deadline constraint. Our proposal addresses fundamental challenges of clouds such as resource elasticity, abundance, and heterogeneity, as well as resource performance variation and virtual machine provisioning delays. The simulation results demonstrate our algorithm’s responsiveness to environmental uncertainties and its ability to generate high-quality schedules that comply with the budget constraint while achieving faster execution times when compared to state-of-the-art algorithms.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {may},
articleno = {5},
numpages = {22},
keywords = {makespan minimisation, scientific workflow, IaaS cloud, Budget, scheduling, resource provisioning}
}

@article{10.14778/1920841.1920906,
author = {Nykiel, Tomasz and Potamias, Michalis and Mishra, Chaitanya and Kollios, George and Koudas, Nick},
title = {MRShare: Sharing across Multiple Queries in MapReduce},
year = {2010},
issue_date = {September 2010},
publisher = {VLDB Endowment},
volume = {3},
number = {1–2},
issn = {2150-8097},
url = {https://doi.org/10.14778/1920841.1920906},
doi = {10.14778/1920841.1920906},
abstract = {Large-scale data analysis lies in the core of modern enterprises and scientific research. With the emergence of cloud computing, the use of an analytical query processing infrastructure (e.g., Amazon EC2) can be directly mapped to monetary value. MapReduce has been a popular framework in the context of cloud computing, designed to serve long running queries (jobs) which can be processed in batch mode. Taking into account that different jobs often perform similar work, there are many opportunities for sharing. In principle, sharing similar work reduces the overall amount of work, which can lead to reducing monetary charges incurred while utilizing the processing infrastructure. In this paper we propose a sharing framework tailored to MapReduce.Our framework, MRShare, transforms a batch of queries into a new batch that will be executed more efficiently, by merging jobs into groups and evaluating each group as a single query. Based on our cost model for MapReduce, we define an optimization problem and we provide a solution that derives the optimal grouping of queries. Experiments in our prototype, built on top of Hadoop, demonstrate the overall effectiveness of our approach and substantial savings.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {494–505},
numpages = {12}
}

@article{10.1145/2560796,
author = {Nykiel, Tomasz and Potamias, Michalis and Mishra, Chaitanya and Kollios, George and Koudas, Nick},
title = {Sharing across Multiple MapReduce Jobs},
year = {2014},
issue_date = {May 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {2},
issn = {0362-5915},
url = {https://doi.org/10.1145/2560796},
doi = {10.1145/2560796},
abstract = {Large-scale data analysis lies in the core of modern enterprises and scientific research. With the emergence of cloud computing, the use of an analytical query processing infrastructure can be directly associated with monetary cost. MapReduce has been a popular framework in the context of cloud computing, designed to serve long-running queries (jobs) which can be processed in batch mode. Taking into account that different jobs often perform similar work, there are many opportunities for sharing. In principle, sharing similar work reduces the overall amount of work, which can lead to reducing monetary charges for utilizing the processing infrastructure. In this article we present a sharing framework tailored to MapReduce, namely, <tt>MRShare</tt>.Our framework, <tt>MRShare</tt>, transforms a batch of queries into a new batch that will be executed more efficiently, by merging jobs into groups and evaluating each group as a single query. Based on our cost model for MapReduce, we define an optimization problem and we provide a solution that derives the optimal grouping of queries. Given the query grouping, we merge jobs appropriately and submit them to MapReduce for processing. A key property of <tt>MRShare</tt> is that it is independent of the MapReduce implementation. Experiments with our prototype, built on top of Hadoop, demonstrate the overall effectiveness of our approach.<tt>MRShare</tt> is primarily designed for handling I/O-intensive queries. However, with the development of high-level languages operating on top of MapReduce, user queries executed in this model become more complex and CPU intensive. Commonly, executed queries can be modeled as evaluating pipelines of CPU-expensive filters over the input stream. Examples of such filters include, but are not limited to, index probes, or certain types of joins. In this article we adapt some of the standard techniques for filter ordering used in relational and stream databases, propose their extensions, and implement them through <tt>MRAdaptiveFilter</tt>, an extension of <tt>MRShare</tt> for expensive filter ordering tailored to MapReduce, which allows one to handle both single- and batch-query execution modes. We present an experimental evaluation that demonstrates additional benefits of <tt>MRAdaptiveFilter</tt>, when executing CPU-intensive queries in <tt>MRShare</tt>.},
journal = {ACM Trans. Database Syst.},
month = {may},
articleno = {12},
numpages = {46},
keywords = {systems, query processing, Sharing MapReduce jobs, MapReduce}
}

